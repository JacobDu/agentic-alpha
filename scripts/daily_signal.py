#!/usr/bin/env python3
"""CSI1000 SOTA ç­–ç•¥æ¯æ—¥ä¿¡å·ç”Ÿæˆå™¨ï¼ˆDry-Runï¼‰

æ•°æ®æº: baostock â†’ Qlib æœ¬åœ°æ•°æ®
æ¨¡å‹: XGBoost + LightGBM å‡å€¼é›†æˆ (Rolling 3m)
ç­–ç•¥: TopkDropout (topk=30, n_drop=5, hold_thresh=60)
ç‰¹å¾: Alpha158 + DB å› å­ Top30 (max_per_cat=5)

ç”¨æ³•:
    # é¦–æ¬¡è¿è¡Œï¼ˆè®­ç»ƒæ¨¡å‹ + ç”Ÿæˆä¿¡å·ï¼‰
    uv run python scripts/daily_signal.py --init

    # æ¯æ—¥è¿è¡Œï¼ˆæ›´æ–°æ•°æ® + ç”Ÿæˆä¿¡å·ï¼‰
    uv run python scripts/daily_signal.py

    # å¼ºåˆ¶é‡è®­æ¨¡å‹
    uv run python scripts/daily_signal.py --retrain

    # æŸ¥çœ‹å½“å‰æŒä»“
    uv run python scripts/daily_signal.py --status

è¾“å‡º:
    outputs/dryrun/models/           æ¨¡å‹æ–‡ä»¶ (xgb_*.pkl, lgb_*.pkl)
    outputs/dryrun/portfolio.json    å½“å‰æŒä»“çŠ¶æ€
    outputs/dryrun/signals/          æ¯æ—¥ä¿¡å· (YYYY-MM-DD.json)
    outputs/dryrun/trade_log.csv     äº¤æ˜“è®°å½•
"""
from __future__ import annotations

import argparse
import gc
import json
import os
import pickle
import sys
import time
import warnings
from datetime import datetime, timedelta
from pathlib import Path

import numpy as np
import pandas as pd

warnings.filterwarnings("ignore")

# â”€â”€ è·¯å¾„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = Path(__file__).resolve().parent.parent
if str(ROOT / "src") not in sys.path:
    sys.path.insert(0, str(ROOT / "src"))

DRYRUN_DIR = ROOT / "outputs" / "dryrun"
MODEL_DIR = DRYRUN_DIR / "models"
SIGNAL_DIR = DRYRUN_DIR / "signals"
PORTFOLIO_FILE = DRYRUN_DIR / "portfolio.json"
TRADE_LOG_FILE = DRYRUN_DIR / "trade_log.csv"
STATE_FILE = DRYRUN_DIR / "state.json"

for d in [DRYRUN_DIR, MODEL_DIR, SIGNAL_DIR]:
    d.mkdir(parents=True, exist_ok=True)

# â”€â”€ ç­–ç•¥å‚æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MARKET = "csi1000"
BENCHMARK = "SH000852"
TOPK = 30
N_DROP = 5
HOLD_THRESH = 60
TOPN_FACTORS = 30
MAX_PER_CAT = 5
RETRAIN_FREQ_MONTHS = 3
TRAIN_START = "2018-01-01"

# äº¤æ˜“æˆæœ¬
OPEN_COST = 0.0005   # ä¹°å…¥ 5bp
CLOSE_COST = 0.0015  # å–å‡º 15bp
MIN_COST = 5

# XGBoost å‚æ•°
XGB_PARAMS = dict(
    objective="reg:squarederror",
    max_depth=8, eta=0.05,
    colsample_bytree=0.8879, subsample=0.8789,
    alpha=205.6999, reg_lambda=580.9768,
    nthread=8,
)

# LightGBM å‚æ•°
LGB_PARAMS = dict(
    loss="mse",
    colsample_bytree=0.8879, learning_rate=0.05,
    subsample=0.8789, lambda_l1=205.6999, lambda_l2=580.9768,
    max_depth=8, num_leaves=128, num_threads=8,
    n_estimators=1000, early_stopping_rounds=50,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  1. æ•°æ®æ›´æ–° (baostock â†’ Qlib)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def update_data_from_baostock():
    """è°ƒç”¨å·²æœ‰çš„ baostock æ•°æ®ä¸‹è½½è„šæœ¬ï¼Œå¢é‡æ›´æ–° Qlib æ•°æ®ã€‚"""
    print("=" * 60)
    print("[æ•°æ®æ›´æ–°] é€šè¿‡ baostock å¢é‡æ›´æ–°è¡Œæƒ…æ•°æ®...")
    script = ROOT / ".agents/skills/qlib-env-data-prep/scripts/download_financial_data.py"
    if not script.exists():
        print(f"  âš  æ•°æ®æ›´æ–°è„šæœ¬ä¸å­˜åœ¨: {script}")
        print("  è·³è¿‡æ•°æ®æ›´æ–°ï¼Œä½¿ç”¨æœ¬åœ°å·²æœ‰æ•°æ®")
        return False

    import subprocess
    result = subprocess.run(
        [sys.executable, str(script), "--phase", "1"],
        cwd=str(ROOT),
        capture_output=True, text=True, timeout=600,
    )
    if result.returncode != 0:
        print(f"  âš  æ•°æ®æ›´æ–°å¤±è´¥: {result.stderr[-500:]}")
        return False
    print("  âœ“ æ•°æ®æ›´æ–°å®Œæˆ")
    return True


def init_qlib():
    """åˆå§‹åŒ– Qlibã€‚"""
    import qlib
    try:
        qlib.init(provider_uri=str(ROOT / "data/qlib/cn_data"), region="cn")
    except Exception:
        pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  2. æ¨¡å‹è®­ç»ƒä¸ç®¡ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_dataset(train, valid, test):
    """åˆ›å»º Alpha158 + TopN å› å­æ•°æ®é›†ã€‚"""
    from qlib.data.dataset import DatasetH
    from project_qlib.factors.topn_db import DBAlpha158PlusTopN

    class Handler(DBAlpha158PlusTopN):
        TOPN = TOPN_FACTORS
        MARKET = "csi1000"
        MAX_PER_CAT = MAX_PER_CAT

    label_expr = ["Ref($close, -2) / Ref($close, -1) - 1"]
    label_name = ["LABEL0"]

    handler = Handler(
        instruments=MARKET,
        start_time=train[0], end_time=test[1],
        fit_start_time=train[0], fit_end_time=train[1],
        label=(label_expr, label_name),
    )
    return DatasetH(
        handler=handler,
        segments={"train": train, "valid": valid, "test": test},
    )


def train_xgb(ds):
    """è®­ç»ƒ XGBoost æ¨¡å‹ã€‚"""
    from qlib.contrib.model.xgboost import XGBModel
    model = XGBModel(**XGB_PARAMS)
    model.fit(ds, num_boost_round=1000, early_stopping_rounds=50, verbose_eval=0)
    return model


def train_lgb(ds):
    """è®­ç»ƒ LightGBM æ¨¡å‹ã€‚"""
    from qlib.contrib.model.gbdt import LGBModel
    model = LGBModel(**LGB_PARAMS)
    model.fit(ds)
    return model


def save_model(model, name: str):
    """æŒä¹…åŒ–æ¨¡å‹åˆ°ç£ç›˜ã€‚"""
    path = MODEL_DIR / f"{name}.pkl"
    with open(path, "wb") as f:
        pickle.dump(model, f)
    print(f"  æ¨¡å‹å·²ä¿å­˜: {path.name}")


def load_model(name: str):
    """ä»ç£ç›˜åŠ è½½æ¨¡å‹ã€‚"""
    path = MODEL_DIR / f"{name}.pkl"
    if not path.exists():
        return None
    with open(path, "rb") as f:
        return pickle.load(f)


def needs_retrain(state: dict) -> bool:
    """æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è®­æ¨¡å‹ï¼ˆè·ä¸Šæ¬¡è®­ç»ƒ >= 3ä¸ªæœˆï¼‰ã€‚"""
    last = state.get("last_retrain")
    if last is None:
        return True
    from dateutil.relativedelta import relativedelta
    last_dt = datetime.strptime(last, "%Y-%m-%d")
    next_retrain = last_dt + relativedelta(months=RETRAIN_FREQ_MONTHS)
    return datetime.now() >= next_retrain


def train_and_save_models(force=False):
    """è®­ç»ƒ XGB+LGB æ¨¡å‹å¹¶ä¿å­˜ã€‚

    è®­ç»ƒé›†: TRAIN_START ~ (å½“å‰æ—¥æœŸ - 1å¹´ - 1å¤©)
    éªŒè¯é›†: (å½“å‰æ—¥æœŸ - 1å¹´) ~ (å½“å‰æ—¥æœŸ - 1å¤©)
    æµ‹è¯•é›†: å½“å‰æ—¥æœŸ ~ æœªæ¥ï¼ˆä»…ç”¨äºç‰¹å¾è®¡ç®—èŒƒå›´ï¼‰
    """
    from dateutil.relativedelta import relativedelta

    state = load_state()
    if not force and not needs_retrain(state):
        print(f"  æ¨¡å‹æ— éœ€é‡è®­ï¼ˆä¸Šæ¬¡è®­ç»ƒ: {state['last_retrain']}ï¼‰")
        return

    today = datetime.now()
    valid_start = today - relativedelta(years=1)
    train_end = valid_start - relativedelta(days=1)
    valid_end = today - relativedelta(days=1)

    train = (TRAIN_START, train_end.strftime("%Y-%m-%d"))
    valid = (valid_start.strftime("%Y-%m-%d"), valid_end.strftime("%Y-%m-%d"))
    # test segment covers recent data for feature computation
    test = (today.strftime("%Y-%m-%d"), (today + relativedelta(days=30)).strftime("%Y-%m-%d"))

    print(f"\n[æ¨¡å‹è®­ç»ƒ] Ensemble (XGB + LGB)")
    print(f"  è®­ç»ƒé›†: {train[0]} ~ {train[1]}")
    print(f"  éªŒè¯é›†: {valid[0]} ~ {valid[1]}")
    t0 = time.time()

    print("  è®­ç»ƒ XGBoost...")
    ds = create_dataset(train, valid, test)
    xgb_model = train_xgb(ds)
    save_model(xgb_model, "xgb_latest")

    print("  è®­ç»ƒ LightGBM...")
    lgb_model = train_lgb(ds)
    save_model(lgb_model, "lgb_latest")

    del ds
    gc.collect()

    state["last_retrain"] = today.strftime("%Y-%m-%d")
    state["train_range"] = f"{train[0]} ~ {train[1]}"
    state["valid_range"] = f"{valid[0]} ~ {valid[1]}"
    save_state(state)
    print(f"  âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ [{time.time()-t0:.0f}s]")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  3. æ¯æ—¥é¢„æµ‹ä¸ä¿¡å·ç”Ÿæˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_today_scores() -> pd.Series:
    """ç”¨ Ensemble æ¨¡å‹å¯¹æ‰€æœ‰ CSI1000 æˆåˆ†è‚¡æ‰“åˆ†ã€‚

    è¿”å› Seriesï¼Œindex = (date, instrument), value = score
    """
    from dateutil.relativedelta import relativedelta

    xgb_model = load_model("xgb_latest")
    lgb_model = load_model("lgb_latest")

    if xgb_model is None or lgb_model is None:
        raise RuntimeError("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ --init æˆ– --retrain")

    state = load_state()
    today = datetime.now()
    # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®æ¥è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆAlpha158 éœ€è¦çº¦ 240 ä¸ªäº¤æ˜“æ—¥ï¼‰
    feat_start = today - relativedelta(years=2)
    feat_end = today + relativedelta(days=5)

    train_range = state.get("train_range", f"{TRAIN_START} ~ 2024-12-31")
    train_start, train_end = train_range.split(" ~ ")

    ds = create_dataset(
        train=(train_start, train_end),
        valid=(train_end, today.strftime("%Y-%m-%d")),
        test=(today.strftime("%Y-%m-%d"), feat_end.strftime("%Y-%m-%d")),
    )

    # XGB é¢„æµ‹
    p_xgb = xgb_model.predict(ds)
    if isinstance(p_xgb, pd.DataFrame):
        p_xgb = p_xgb.iloc[:, 0]

    # LGB é¢„æµ‹
    p_lgb = lgb_model.predict(ds)
    if isinstance(p_lgb, pd.DataFrame):
        p_lgb = p_lgb.iloc[:, 0]

    # Ensemble: ç®€å•å¹³å‡
    idx = p_xgb.index.intersection(p_lgb.index)
    scores = (p_xgb.loc[idx] + p_lgb.loc[idx]) / 2
    scores.name = "score"

    del ds, xgb_model, lgb_model
    gc.collect()

    return scores


def generate_signals(scores: pd.Series, trade_date: str) -> dict:
    """åŸºäº TopkDropout é€»è¾‘ç”Ÿæˆä¹°å–ä¿¡å·ã€‚

    å‚æ•°:
        scores: å…¨å¸‚åœºè‚¡ç¥¨é¢„æµ‹åˆ†æ•°
        trade_date: äº¤æ˜“æ—¥æœŸ YYYY-MM-DD

    è¿”å›:
        ä¿¡å·å­—å…¸ï¼ŒåŒ…å« buy/sell/hold åˆ—è¡¨
    """
    portfolio = load_portfolio()
    current_holdings = set(portfolio.get("holdings", {}).keys())

    # è·å–å½“æ—¥æ‰€æœ‰è‚¡ç¥¨åˆ†æ•°å¹¶æ’å
    # scores çš„ index æ˜¯ MultiIndex(date, instrument)
    # å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
    if isinstance(scores.index, pd.MultiIndex):
        dates = scores.index.get_level_values(0).unique()
        # å– <= trade_date çš„æœ€è¿‘ä¸€å¤©
        valid_dates = [d for d in dates if str(d)[:10] <= trade_date]
        if not valid_dates:
            print(f"  âš  æ— æ³•æ‰¾åˆ° {trade_date} æˆ–ä¹‹å‰çš„é¢„æµ‹æ•°æ®")
            return {"date": trade_date, "buy": [], "sell": [], "hold": list(current_holdings)}
        latest_date = max(valid_dates)
        day_scores = scores.xs(latest_date, level=0)
    else:
        day_scores = scores

    day_scores = day_scores.dropna().sort_values(ascending=False)

    # â”€â”€ TopkDropout é€»è¾‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    top_instruments = set(day_scores.index[:HOLD_THRESH])  # æ’ååœ¨ hold_thresh å†…çš„è‚¡ç¥¨
    top_k = set(day_scores.index[:TOPK])  # æ’ååœ¨ topk å†…çš„è‚¡ç¥¨

    # éœ€è¦å–å‡ºçš„: å½“å‰æŒä»“ä¸­æ’åè·Œå‡º hold_thresh çš„
    to_sell_candidates = current_holdings - top_instruments
    # é™åˆ¶æ¯å¤©æœ€å¤šå–å‡º n_drop åª
    to_sell = set(list(to_sell_candidates)[:N_DROP])

    # å–å‡ºåçš„æŒä»“
    after_sell = current_holdings - to_sell

    # éœ€è¦è¡¥å……åˆ° topk çš„æŒä»“æ•°
    n_to_buy = TOPK - len(after_sell)

    # ä» top_k ä¸­é€‰æ‹©ä¸åœ¨ç°æœ‰æŒä»“ä¸­çš„
    buy_candidates = [s for s in day_scores.index if s in top_k and s not in after_sell]
    to_buy = buy_candidates[:max(0, n_to_buy)]

    # ç»§ç»­æŒæœ‰çš„
    to_hold = list(after_sell)

    # æ„å»ºä¿¡å·
    signal = {
        "date": trade_date,
        "model_date": str(latest_date)[:10] if isinstance(scores.index, pd.MultiIndex) else trade_date,
        "total_scored": len(day_scores),
        "buy": [],
        "sell": [],
        "hold": [],
        "portfolio_size_before": len(current_holdings),
        "portfolio_size_after": len(after_sell) + len(to_buy),
    }

    # ä¹°å…¥ä¿¡å·ï¼ˆé™„å¸¦åˆ†æ•°å’Œæ’åï¼‰
    for inst in to_buy:
        rank = list(day_scores.index).index(inst) + 1
        signal["buy"].append({
            "instrument": inst,
            "score": round(float(day_scores[inst]), 6),
            "rank": rank,
            "estimated_cost": f"{OPEN_COST * 100:.2f}%",
        })

    # å–å‡ºä¿¡å·
    for inst in to_sell:
        rank = list(day_scores.index).index(inst) + 1 if inst in day_scores.index else -1
        signal["sell"].append({
            "instrument": inst,
            "score": round(float(day_scores.get(inst, 0)), 6),
            "rank": rank,
            "reason": "æ’åè·Œå‡º hold_thresh" if rank > HOLD_THRESH else "æ¸…é€€",
            "estimated_cost": f"{CLOSE_COST * 100:.2f}%",
        })

    # æŒæœ‰ä¿¡å·
    for inst in sorted(to_hold):
        rank = list(day_scores.index).index(inst) + 1 if inst in day_scores.index else -1
        signal["hold"].append({
            "instrument": inst,
            "score": round(float(day_scores.get(inst, 0)), 6),
            "rank": rank,
        })

    return signal


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  4. ç»„åˆçŠ¶æ€ç®¡ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_portfolio() -> dict:
    """åŠ è½½å½“å‰æŒä»“ã€‚"""
    if PORTFOLIO_FILE.exists():
        return json.load(open(PORTFOLIO_FILE))
    return {"holdings": {}, "cash": 1e8, "last_update": None}


def save_portfolio(portfolio: dict):
    """ä¿å­˜æŒä»“çŠ¶æ€ã€‚"""
    with open(PORTFOLIO_FILE, "w") as f:
        json.dump(portfolio, f, indent=2, ensure_ascii=False)


def load_state() -> dict:
    """åŠ è½½ç³»ç»ŸçŠ¶æ€ã€‚"""
    if STATE_FILE.exists():
        return json.load(open(STATE_FILE))
    return {}


def save_state(state: dict):
    """ä¿å­˜ç³»ç»ŸçŠ¶æ€ã€‚"""
    with open(STATE_FILE, "w") as f:
        json.dump(state, f, indent=2, ensure_ascii=False)


def update_portfolio(signal: dict):
    """æ ¹æ®ä¿¡å·æ›´æ–°æŒä»“ã€‚"""
    portfolio = load_portfolio()
    holdings = portfolio.get("holdings", {})

    # æ‰§è¡Œå–å‡º
    for s in signal["sell"]:
        inst = s["instrument"]
        if inst in holdings:
            del holdings[inst]

    # æ‰§è¡Œä¹°å…¥
    for b in signal["buy"]:
        inst = b["instrument"]
        holdings[inst] = {
            "entry_date": signal["date"],
            "entry_score": b["score"],
            "entry_rank": b["rank"],
        }

    portfolio["holdings"] = holdings
    portfolio["last_update"] = signal["date"]
    save_portfolio(portfolio)


def save_signal(signal: dict):
    """ä¿å­˜æ¯æ—¥ä¿¡å·åˆ°æ–‡ä»¶ã€‚"""
    path = SIGNAL_DIR / f"{signal['date']}.json"
    with open(path, "w") as f:
        json.dump(signal, f, indent=2, ensure_ascii=False)
    print(f"  ä¿¡å·å·²ä¿å­˜: {path.name}")


def append_trade_log(signal: dict):
    """è¿½åŠ äº¤æ˜“è®°å½•åˆ° CSVã€‚"""
    rows = []
    for b in signal["buy"]:
        rows.append({
            "date": signal["date"],
            "action": "BUY",
            "instrument": b["instrument"],
            "score": b["score"],
            "rank": b["rank"],
        })
    for s in signal["sell"]:
        rows.append({
            "date": signal["date"],
            "action": "SELL",
            "instrument": s["instrument"],
            "score": s["score"],
            "rank": s["rank"],
            "reason": s.get("reason", ""),
        })

    if not rows:
        return

    df = pd.DataFrame(rows)
    header = not TRADE_LOG_FILE.exists()
    df.to_csv(TRADE_LOG_FILE, mode="a", header=header, index=False)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  5. ä¸»æµç¨‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def print_signal_summary(signal: dict):
    """æ‰“å°ä¿¡å·æ‘˜è¦ã€‚"""
    print(f"\n{'='*60}")
    print(f"ğŸ“… äº¤æ˜“æ—¥: {signal['date']}  (æ¨¡å‹æ•°æ®æ—¥: {signal.get('model_date', '?')})")
    print(f"ğŸ“Š æ‰“åˆ†è‚¡ç¥¨æ•°: {signal['total_scored']}")
    print(f"ğŸ“ ç»„åˆ: {signal['portfolio_size_before']} â†’ {signal['portfolio_size_after']} åª")
    print(f"{'='*60}")

    if signal["buy"]:
        print(f"\nğŸŸ¢ ä¹°å…¥ ({len(signal['buy'])} åª):")
        print(f"  {'è‚¡ç¥¨':<12} {'åˆ†æ•°':>10} {'æ’å':>6} {'æˆæœ¬':>8}")
        print(f"  {'-'*40}")
        for b in signal["buy"]:
            print(f"  {b['instrument']:<12} {b['score']:>10.6f} {b['rank']:>6d} {b['estimated_cost']:>8}")

    if signal["sell"]:
        print(f"\nğŸ”´ å–å‡º ({len(signal['sell'])} åª):")
        print(f"  {'è‚¡ç¥¨':<12} {'åˆ†æ•°':>10} {'æ’å':>6} {'åŸå› ':<20}")
        print(f"  {'-'*52}")
        for s in signal["sell"]:
            print(f"  {s['instrument']:<12} {s['score']:>10.6f} {s['rank']:>6d} {s.get('reason',''):<20}")

    if signal["hold"]:
        print(f"\nâšª æŒæœ‰ ({len(signal['hold'])} åª):")
        top5 = sorted(signal["hold"], key=lambda x: x["rank"])[:5]
        for h in top5:
            print(f"  {h['instrument']:<12} rank={h['rank']:>4d}  score={h['score']:.6f}")
        if len(signal["hold"]) > 5:
            print(f"  ... åŠå…¶ä»– {len(signal['hold'])-5} åª")

    if not signal["buy"] and not signal["sell"]:
        print("\n  â„¹ ä»Šæ—¥æ— äº¤æ˜“ä¿¡å·")

    print()


def cmd_init(args):
    """åˆå§‹åŒ–ï¼šæ›´æ–°æ•°æ® + è®­ç»ƒæ¨¡å‹ + ç”Ÿæˆé¦–æ—¥ä¿¡å·ã€‚"""
    print("ğŸš€ åˆå§‹åŒ– CSI1000 SOTA ç­–ç•¥ Dry-Run")
    print(f"   ç­–ç•¥: Ensemble(XGB+LGB) + TopkDropout(tk={TOPK}, drop={N_DROP}, hold={HOLD_THRESH})")
    print(f"   ç‰¹å¾: Alpha158 + DBå› å­Top{TOPN_FACTORS} (mpc={MAX_PER_CAT})")

    # 1. æ›´æ–°æ•°æ®
    update_data_from_baostock()

    # 2. åˆå§‹åŒ– Qlib
    init_qlib()

    # 3. è®­ç»ƒæ¨¡å‹
    train_and_save_models(force=True)

    # 4. ç”Ÿæˆé¦–æ—¥ä¿¡å·
    print("\n[é¦–æ—¥ä¿¡å·ç”Ÿæˆ]")
    scores = get_today_scores()
    today = datetime.now().strftime("%Y-%m-%d")
    signal = generate_signals(scores, today)
    save_signal(signal)
    update_portfolio(signal)
    append_trade_log(signal)
    print_signal_summary(signal)

    print("âœ… åˆå§‹åŒ–å®Œæˆ! åç»­æ¯æ—¥è¿è¡Œ: uv run python scripts/daily_signal.py")


def cmd_daily(args):
    """æ¯æ—¥è¿è¡Œï¼šæ›´æ–°æ•°æ® + æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è®­ + ç”Ÿæˆä¿¡å·ã€‚"""
    today = datetime.now().strftime("%Y-%m-%d")
    print(f"ğŸ“… æ¯æ—¥ä¿¡å·ç”Ÿæˆ: {today}")

    # æ£€æŸ¥ä¿¡å·æ˜¯å¦å·²å­˜åœ¨
    signal_file = SIGNAL_DIR / f"{today}.json"
    if signal_file.exists() and not args.force:
        print(f"  âš  ä»Šæ—¥ä¿¡å·å·²ç”Ÿæˆ: {signal_file.name}")
        signal = json.load(open(signal_file))
        print_signal_summary(signal)
        return

    # 1. æ›´æ–°æ•°æ®
    update_data_from_baostock()

    # 2. åˆå§‹åŒ– Qlib
    init_qlib()

    # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è®­
    state = load_state()
    if needs_retrain(state):
        print("\n[æ¨¡å‹é‡è®­] è·ä¸Šæ¬¡è®­ç»ƒå·²æ»¡ 3 ä¸ªæœˆ")
        train_and_save_models(force=True)
    else:
        print(f"  æ¨¡å‹çŠ¶æ€: ä¸Šæ¬¡è®­ç»ƒ {state.get('last_retrain', 'æœªçŸ¥')}")

    # 4. ç”Ÿæˆä¿¡å·
    print("\n[ä¿¡å·ç”Ÿæˆ]")
    scores = get_today_scores()
    signal = generate_signals(scores, today)
    save_signal(signal)
    update_portfolio(signal)
    append_trade_log(signal)
    print_signal_summary(signal)


def cmd_retrain(args):
    """å¼ºåˆ¶é‡è®­æ¨¡å‹ã€‚"""
    print("ğŸ”„ å¼ºåˆ¶é‡è®­æ¨¡å‹")
    update_data_from_baostock()
    init_qlib()
    train_and_save_models(force=True)


def cmd_status(args):
    """æŸ¥çœ‹å½“å‰çŠ¶æ€ã€‚"""
    print("ğŸ“Š CSI1000 SOTA ç­–ç•¥çŠ¶æ€")
    print(f"{'='*60}")

    # ç³»ç»ŸçŠ¶æ€
    state = load_state()
    print(f"\n  ä¸Šæ¬¡è®­ç»ƒ: {state.get('last_retrain', 'æœªè®­ç»ƒ')}")
    print(f"  è®­ç»ƒåŒºé—´: {state.get('train_range', '--')}")
    print(f"  éªŒè¯åŒºé—´: {state.get('valid_range', '--')}")

    retrain_needed = needs_retrain(state)
    print(f"  éœ€è¦é‡è®­: {'æ˜¯ âš ' if retrain_needed else 'å¦ âœ“'}")

    # æ¨¡å‹æ–‡ä»¶
    xgb_exists = (MODEL_DIR / "xgb_latest.pkl").exists()
    lgb_exists = (MODEL_DIR / "lgb_latest.pkl").exists()
    print(f"\n  XGB æ¨¡å‹: {'âœ“ å·²ä¿å­˜' if xgb_exists else 'âœ— ä¸å­˜åœ¨'}")
    print(f"  LGB æ¨¡å‹: {'âœ“ å·²ä¿å­˜' if lgb_exists else 'âœ— ä¸å­˜åœ¨'}")

    # æŒä»“
    portfolio = load_portfolio()
    holdings = portfolio.get("holdings", {})
    print(f"\n  æŒä»“æ•°é‡: {len(holdings)} åª")
    print(f"  æœ€åæ›´æ–°: {portfolio.get('last_update', '--')}")

    if holdings:
        print(f"\n  æŒä»“åˆ—è¡¨:")
        for inst, info in sorted(holdings.items()):
            entry = info.get("entry_date", "?")
            print(f"    {inst:<12} å…¥åœº={entry}  rank={info.get('entry_rank', '?')}")

    # ä¿¡å·å†å²
    signals = sorted(SIGNAL_DIR.glob("*.json"))
    print(f"\n  å†å²ä¿¡å·: {len(signals)} å¤©")
    if signals:
        latest = signals[-1]
        print(f"  æœ€æ–°ä¿¡å·: {latest.stem}")

    # äº¤æ˜“è®°å½•
    if TRADE_LOG_FILE.exists():
        df = pd.read_csv(TRADE_LOG_FILE)
        n_buy = len(df[df["action"] == "BUY"])
        n_sell = len(df[df["action"] == "SELL"])
        print(f"\n  äº¤æ˜“è®°å½•: {len(df)} ç¬” (ä¹°å…¥ {n_buy}, å–å‡º {n_sell})")

    print()


def main():
    parser = argparse.ArgumentParser(
        description="CSI1000 SOTA ç­–ç•¥æ¯æ—¥ä¿¡å·ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    sub = parser.add_subparsers(dest="command")

    # é»˜è®¤ï¼šæ¯æ—¥è¿è¡Œï¼ˆæ— å­å‘½ä»¤æ—¶ï¼‰
    parser.add_argument("--init", action="store_true", help="é¦–æ¬¡åˆå§‹åŒ–ï¼ˆè®­ç»ƒæ¨¡å‹ + ç”Ÿæˆä¿¡å·ï¼‰")
    parser.add_argument("--retrain", action="store_true", help="å¼ºåˆ¶é‡è®­æ¨¡å‹")
    parser.add_argument("--status", action="store_true", help="æŸ¥çœ‹å½“å‰çŠ¶æ€")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ç”Ÿæˆä»Šæ—¥ä¿¡å·")

    args = parser.parse_args()

    if args.init:
        cmd_init(args)
    elif args.retrain:
        cmd_retrain(args)
    elif args.status:
        cmd_status(args)
    else:
        cmd_daily(args)


if __name__ == "__main__":
    main()
